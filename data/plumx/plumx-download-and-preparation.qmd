---
title: "Download and prepare data from PlumX API"
engine: knitr
---
First we select the list of DOIs:

```{r}
library(readxl)
library(dplyr)
library(RefManageR)
library(purrr)
library(foreach)
library(jsonlite)
here::i_am("data/plumx/plumx-download-and-preparation.qmd")
bib1 <- ReadBib(here::here("bibTeX","peer-review.bibtex"), check = FALSE)

CRediT_folder <- "data"
credit <-read_excel(here::here(CRediT_folder, "CRediT-my-publications.xlsx"), 
                    "Contributions per pub") 
dois <- credit |> filter(!is.na(doi)) |> pull(doi)

conn <- file(here::here("data/plumx/","doi-list"), "w")
writeLines(dois,conn)
close(conn)
```

Now we run this to query plumx API (need to run this in the UNSW network to get access to the service, VPN is not enough):

```{bash}
source ~/.Renviron

for doi in $(cat doi-list)
do
  sdoi=query-$(echo $doi | sed -e s/\\//_/g).json
  if [ -e $sdoi ]
  then
      echo "skipping $doi"
  else
      wget --output-document=${sdoi} https://api.elsevier.com/analytics/plumx/doi/${doi}?apiKey=${Elsevier_API}
  fi
done
```


Let's wrap the process in a couple of functions:

```{r}
f <- function(x) {
  tibble(!!x$name := x$total) 
}
readPlumxJson <- function(x) {
  if(file.info(x)$size>0) {
    qry <- read_json(x)
  vls <- map(qry$count_categories, 
             function(x) {
               totals <- f(x) 
               counts <- map(x$count_types,f)
               bind_cols(totals, counts)
             }) |> bind_cols()
  rslts <- tibble(doi = qry$id_value) %>% bind_cols(vls)
  }
  else {
    rslts <- tibble()
  }
  rslts
}
```

Read files from folder and `map` function:
```{r}

plumx_folder <- here::here("data/plumx/")
jsonFiles <- dir(plumx_folder, pattern = "json$", full.names = TRUE)
PMX_ALL <- map(jsonFiles, readPlumxJson) |> bind_rows()
```

Save this to a folder:
```{r}

rds_folder <- "data"
saveRDS(PMX_ALL,here::here(rds_folder,"plumx_ALL.rds")) 
```
